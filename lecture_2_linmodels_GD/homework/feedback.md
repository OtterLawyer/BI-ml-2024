# 1.

Производная посчитана правильно! Так держать :)

Градиентный спуск тоде правильно!

На самом деле, в функции с градиентным спуском можно было обойтись и без копирования, потому что потом сразу же `curr_w` будет ссылаться уже на другой элемент (после строчки с шагом спуска `curr_w -= lr * grad_f(curr_w)`)


*Вопрос на засыпку*: попали ли мы в глобальный минимум функции? Сколько у функии $f$ вообще минимумов и максимумов?

# 2

## 2.1

В `mse` делим на размер выборки, а не умножаем. Но вообще, можно сразу одной командой и посчитать (см. код).

С градиентом тоже все правильно, тут можно еще один синтаксический сахар сделать (см. код)

Комментарий тоже в ноутбуке дал по поводу вопроса, но вообще разницы нет в случае с матрицами.

## 2.2

К методу линейной регрессии вопросов нет! Все супер.

## 2.3

Pа пайплайн бонус в 0.25 баллов ты получаешь :) Еще плюс тебе 0.5 хороший репорт с метриками!

Единственное - пиши что за цифры ты выводишь - боссу/заказчику пофиг на код, но цифры надо все пояснять, как и вообще все выводы в консоль/принты в stdout/вывод в файлик! Вон у spades каке логи подробные! Это я ругаюсь на клетку с коэффициентом детерминации.

# 3

## 3.1

К сигмоиде вопросов нет!

## 3.2


Отличная идея изначально предотвратить взрыв в логарифме!  Но зачем клипать сверху? Это лишнее, у тебя иначе никогда не будет `y_pred=1`. Понятно что он стремится к 1, но ты его клипаешь все равно. Хотя `1e-15` не страшно. 


## 3.3

Класс реализовала - все верно! C метриками тоже все супер сделано!

## 3.4

За подробный EDA пюсую 0.5 доп баллов! Можно размеры графиков чуть увеличить, а то сжатые получились. И у второго подграфика легенда съехала влево. 



Еще можно улучшит скор тем, что ты обработаешь категориальные фичи к примеру `OneHotEncoder`-ом, а не обрабатывать их вместе с другими.

Но за пайплайн +0.25 заслуженно.

Confusion matrix супер

За анализ большой респект! 


Feature importance забыл посмотреть. Вынужден снять четверть балла. Как нам посмотреть feature importance? Можно удалять фичи и смотреть, какие при удалении снижают скор и насколько. Можно посмортеть на коэффициенты, которые получились - если они высокие и ненулевые - то можно говорить, что для модели они важны, в какой-то степени. На это смотрят, но не часто.


# 4

Класс, впервые познакомился с этими исполнителями, спасибо тебе!

ИТОГ:

1 - 1/1
2.1 - 2/2
2.2 - 3/3
2.3 - 4/4 + 0.75 (допы)
3.1 - 0.5/0.5
3.2 - 2/2.5
3.3 - 2/2
3.4 - 4.75/5 + 0.75
4 - 0.5/0.5


ШТРАФ: Папку с данными и с кодом ты не сделал, а соблюдать иерархию проекта - важно. Поэтому вынужден снять четверть балла

СУММА: 19.75 + 2 доп - 0.25 штраф = 21.5 баллов
